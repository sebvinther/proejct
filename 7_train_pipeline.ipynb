{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/564374\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import hopsworks\n",
    "import hsfs\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler  # Import StandardScaler from scikit-learn\n",
    "import joblib\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#Connecting to hopsworks\n",
    "api_key = os.environ.get('hopsworks_api')\n",
    "project = hopsworks.login(api_key_value=api_key)\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "#Another connection to hopsworks\n",
    "api_key = os.getenv('hopsworks_api')\n",
    "connection = hsfs.connection()\n",
    "fs = connection.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the feature view\n",
    "feature_view = fs.get_feature_view(\n",
    "    name='nvidia_stocks_fv',\n",
    "    version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up train & test split dates\n",
    "train_start = \"2022-03-10\"\n",
    "train_end = \"2023-11-30\"\n",
    "\n",
    "test_start = '2024-02-02'\n",
    "test_end = \"2024-04-07\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/564374/jobs/named/nvidia_stocks_fv_1_create_fv_td_05082024181504/executions\n",
      "2024-08-05 20:16:55,855 WARNING: VersionWarning: Incremented version to `1`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, <hsfs.core.job.Job at 0x1f386853650>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the train/test split on the feature view with the split dates\n",
    "feature_view.create_train_test_split(\n",
    "    train_start=train_start,\n",
    "    train_end=train_end,\n",
    "    test_start=test_start,\n",
    "    test_end=test_end,\n",
    "    data_format='csv',\n",
    "    coalesce= True,\n",
    "    statistics_config={'histogram':True,'correlations':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the split from feature view\n",
    "X_train, X_test, y_train, y_test = feature_view.get_train_test_split(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-24T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>-0.018171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-23T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.125840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-17T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.339410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-18T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.339410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-27T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>-0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2022-11-15T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.091602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2023-02-02T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.065004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2023-05-22T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>-0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2023-10-04T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.024545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2023-04-13T00:00:00.000Z</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.204008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date ticker  sentiment\n",
       "0    2023-07-24T00:00:00.000Z   NVDA  -0.018171\n",
       "1    2023-08-23T00:00:00.000Z   NVDA   0.125840\n",
       "2    2022-10-17T00:00:00.000Z   NVDA   0.339410\n",
       "3    2022-10-18T00:00:00.000Z   NVDA   0.339410\n",
       "4    2023-04-27T00:00:00.000Z   NVDA  -0.095000\n",
       "..                        ...    ...        ...\n",
       "296  2022-11-15T00:00:00.000Z   NVDA   0.091602\n",
       "297  2023-02-02T00:00:00.000Z   NVDA   0.065004\n",
       "298  2023-05-22T00:00:00.000Z   NVDA  -0.095000\n",
       "299  2023-10-04T00:00:00.000Z   NVDA   0.024545\n",
       "300  2023-04-13T00:00:00.000Z   NVDA   0.204008\n",
       "\n",
       "[301 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting date into datetime\n",
    "X_train['date'] = pd.to_datetime(X_train['date']).dt.date\n",
    "X_test['date'] = pd.to_datetime(X_test['date']).dt.date\n",
    "X_train['date'] = pd.to_datetime(X_train['date'])\n",
    "X_test['date'] = pd.to_datetime(X_test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>-0.018171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.125840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.339410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.339410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>-0.095000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker  sentiment\n",
       "0 2023-07-24   NVDA  -0.018171\n",
       "1 2023-08-23   NVDA   0.125840\n",
       "2 2022-10-17   NVDA   0.339410\n",
       "3 2022-10-18   NVDA   0.339410\n",
       "4 2023-04-27   NVDA  -0.095000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the 'ticker' column\n",
    "tickers = X_train[['ticker']]\n",
    "\n",
    "# Initializing OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fitting and transforming the 'ticker' column\n",
    "ticker_encoded = encoder.fit_transform(tickers)\n",
    "\n",
    "# Converting the encoded column into a DataFrame\n",
    "ticker_encoded_df = pd.DataFrame(ticker_encoded.toarray(), columns=encoder.get_feature_names_out(['ticker']))\n",
    "\n",
    "# Concatenating the encoded DataFrame with the original DataFrame\n",
    "X_train = pd.concat([X_train, ticker_encoded_df], axis=1)\n",
    "\n",
    "# Dropping the original 'ticker' column\n",
    "X_train.drop('ticker', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ticker_NVDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>-0.018171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>0.125840</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>-0.095000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sentiment  ticker_NVDA\n",
       "0 2023-07-24  -0.018171          1.0\n",
       "1 2023-08-23   0.125840          1.0\n",
       "2 2022-10-17   0.339410          1.0\n",
       "3 2022-10-18   0.339410          1.0\n",
       "4 2023-04-27  -0.095000          1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecting X train after onehotencoding 'Ticker'\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the same for X test as done to X train\n",
    "\n",
    "tickers = X_test[['ticker']]\n",
    "\n",
    "# Initializing OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fitting and transforming the 'ticker' column\n",
    "ticker_encoded_test = encoder.fit_transform(tickers)\n",
    "\n",
    "# Converting the encoded column into a DataFrame\n",
    "ticker_encoded_df_test = pd.DataFrame(ticker_encoded_test.toarray(), columns=encoder.get_feature_names_out(['ticker']))\n",
    "\n",
    "# Concatenating the encoded DataFrame with the original DataFrame\n",
    "X_test = pd.concat([X_test, ticker_encoded_df_test], axis=1)\n",
    "\n",
    "# Dropping the original 'ticker' column\n",
    "X_test.drop('ticker', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in MinMaxScaler to be used on the target variable 'open'\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fitting and transforming the 'open' column\n",
    "#y_train['open_scaled'] = scaler.fit_transform(y_train[['open']])\n",
    "#y_train.drop('open', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the same to y_test as done to y_train \n",
    "#y_test['open_scaled'] = scaler.fit_transform(y_test[['open']])\n",
    "#y_test.drop('open', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function for the LSTM model\n",
    "def create_model(input_shape,\n",
    "                 LSTM_filters=64,\n",
    "                 dropout=0.1,\n",
    "                 recurrent_dropout=0.1,\n",
    "                 dense_dropout=0.5,\n",
    "                 activation='relu',\n",
    "                 depth=1):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    if depth > 1:\n",
    "        for i in range(1, depth):\n",
    "            # Recurrent layer\n",
    "            model.add(LSTM(LSTM_filters, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "\n",
    "    # Recurrent layer\n",
    "    model.add(LSTM(LSTM_filters, return_sequences=False, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "\n",
    "    # Fully connected layer\n",
    "    if activation == 'relu':\n",
    "        model.add(Dense(LSTM_filters, activation='relu'))\n",
    "    elif activation == 'leaky_relu':\n",
    "        model.add(Dense(LSTM_filters))\n",
    "        model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "    # Dropout for regularization\n",
    "    model.add(Dropout(dense_dropout))\n",
    "\n",
    "    # Output layer for predicting one day forward\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model\n",
    "# As X_train['date'] column exists and is in datetime format, we're converting it\n",
    "X_train['year'] = X_train['date'].dt.year\n",
    "X_train['month'] = X_train['date'].dt.month\n",
    "X_train['day'] = X_train['date'].dt.day\n",
    "\n",
    "# Dropping the original date column\n",
    "X_train.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "X_train_array = X_train.to_numpy()\n",
    "\n",
    "# Reshaping the array to have a shape suitable for LSTM\n",
    "X_train_array = np.expand_dims(X_train_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to numpy array\n",
    "X_train_array = X_train.values\n",
    "\n",
    "# Reshaping X_train_array to add a time step dimension\n",
    "X_train_reshaped = X_train_array.reshape(X_train_array.shape[0], 1, X_train_array.shape[1])\n",
    "\n",
    "# Assuming X_train_reshaped shape is now (374, 1, 5)\n",
    "input_shape = X_train_reshaped.shape[1:]\n",
    "\n",
    "# Create the model\n",
    "model = create_model(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 103222.2031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f3868b0a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model on the training dataset\n",
    "model.fit(X_train_reshaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As X_test['date'] column exists and is in datetime format, we're converting it\n",
    "X_test['year'] = X_test['date'].dt.year\n",
    "X_test['month'] = X_test['date'].dt.month\n",
    "X_test['day'] = X_test['date'].dt.day\n",
    "\n",
    "# Dropping the original date column\n",
    "X_test.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "X_test_array = X_test.to_numpy()\n",
    "\n",
    "# Reshape the array to have a shape suitable for LSTM\n",
    "X_test_array = np.expand_dims(X_test_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "Root Mean Squared Error (RMSE): 825.2002706410944\n"
     ]
    }
   ],
   "source": [
    "# Predicting y_pred with X_test\n",
    "y_pred = model.predict(X_test_array)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "#Conneting to hopsworks model registry\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 301 entries, 0 to 300\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    301 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 2.5 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.222282 ],\n",
       "       [2.222673 ],\n",
       "       [2.22254  ],\n",
       "       [2.2230124],\n",
       "       [2.222834 ],\n",
       "       [2.2221904],\n",
       "       [2.2232728],\n",
       "       [2.2233815],\n",
       "       [2.22323  ],\n",
       "       [2.2225304],\n",
       "       [2.2229786],\n",
       "       [2.222435 ],\n",
       "       [2.222715 ],\n",
       "       [2.223219 ],\n",
       "       [2.2228637],\n",
       "       [2.2222707],\n",
       "       [2.2232022],\n",
       "       [2.2229006],\n",
       "       [2.2230384],\n",
       "       [2.2225761],\n",
       "       [2.2230706],\n",
       "       [2.223246 ],\n",
       "       [2.22215  ],\n",
       "       [2.2234044],\n",
       "       [2.222944 ],\n",
       "       [2.2230055],\n",
       "       [2.2232988],\n",
       "       [2.223102 ],\n",
       "       [2.2226205],\n",
       "       [2.2234266],\n",
       "       [2.2230833],\n",
       "       [2.2232833],\n",
       "       [2.2231324],\n",
       "       [2.2220337],\n",
       "       [2.222756 ],\n",
       "       [2.2227955],\n",
       "       [2.2220926],\n",
       "       [2.223031 ],\n",
       "       [2.2227874],\n",
       "       [2.2232568],\n",
       "       [2.2224832],\n",
       "       [2.223358 ],\n",
       "       [2.222826 ],\n",
       "       [2.2227473]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RMSE': 825.2002706410944}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute RMSE metric for filling the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse_metrics = {\"RMSE\": rmse}\n",
    "rmse_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the model schema\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a file called 'stock_model'\n",
    "model_dir=\"stock_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model to hopsworks model registry\n",
    "#stock_pred_model = mr.tensorflow.create_model(\n",
    "#        name=\"stock_pred_model\",\n",
    "#        metrics= rmse_metrics,\n",
    "#        model_schema=model_schema,\n",
    "#        description=\"Stock Market NVDA Predictor from News Sentiment\",\n",
    "#    )\n",
    "\n",
    "#stock_pred_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e4afe3c67046f09b691f8f8d372ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c9e254cf1d42ba8e2c60867a7fbb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/292331 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe716e936f9b4dd882b226ebf2e6f959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/44 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8356a22d3d6c433da4329c109bf960af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/554 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/564374/models/stock_pred_model/1\n"
     ]
    }
   ],
   "source": [
    "def register_tensorflow_model(model, name, description, features, labels, metrics):\n",
    "    from hsml.schema import Schema\n",
    "    from hsml.model_schema import ModelSchema\n",
    "    import os\n",
    "    import joblib\n",
    "    import shutil\n",
    "\n",
    "    mr = project.get_model_registry()\n",
    "\n",
    "    model_dir= name + \"_model\"\n",
    "    if os.path.isdir(model_dir) == False:\n",
    "        os.mkdir(model_dir)\n",
    "    pickle= name + '_model.pkl'\n",
    "    # This will strip out the sml directory, copying only the files\n",
    "    #shutil.copytree(\"sml\", model_dir, dirs_exist_ok=True) #python 3.8+\n",
    "\n",
    "    joblib.dump(model, model_dir + \"/\" + pickle)\n",
    "\n",
    "    input_example = features.sample()\n",
    "    input_schema = Schema(features)\n",
    "    output_schema = Schema(labels)\n",
    "    model_schema = ModelSchema(input_schema, output_schema)\n",
    "\n",
    "    stock_pred_model = mr.tensorflow.create_model(\n",
    "        name=\"stock_pred_model\", \n",
    "        metrics=rmse_metrics,\n",
    "        model_schema=model_schema,\n",
    "        input_example=input_example, \n",
    "        description=description)\n",
    "\n",
    "    # Save all artifacts in the model directory to the model registry\n",
    "    stock_pred_model.save(model_dir)\n",
    "\n",
    "\n",
    "register_tensorflow_model(model, \"stock_prediction\", \"Stock Prediction\", X_train, y_train, rmse_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
