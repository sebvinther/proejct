{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "from SML.news_preprocessing import process_news_articles    #Importing everything from 'news_preprocessing'\n",
    "from SML.news_preprocessing import exponential_moving_average\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function for fetching news\n",
    "\n",
    "def fetch_news(api_key, ticker, start_date, end_date):\n",
    "    base_url = os.environ.get(\"endpointnewsp\")\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    all_news = []\n",
    "    \n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        batch_end_date = current_date + timedelta(days=50)\n",
    "        if batch_end_date > end_date:\n",
    "            batch_end_date = end_date\n",
    "\n",
    "        params = {\n",
    "            \"ticker\": ticker,\n",
    "            \"published_utc.gte\": current_date.strftime('%Y-%m-%d'),\n",
    "            \"published_utc.lte\": batch_end_date.strftime('%Y-%m-%d'),\n",
    "            \"limit\": 50,\n",
    "            \"sort\": \"published_utc\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(base_url, headers=headers, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                articles = data.get('results', [])\n",
    "                \n",
    "                # Creating a DataFrame from articles\n",
    "                df = pd.DataFrame(articles)\n",
    "                \n",
    "                # Adding primary_key column if ticker is found\n",
    "                df['ticker'] = df['tickers'].apply(lambda x: ticker if ticker in x else None)\n",
    "                \n",
    "                all_news.append(df)  # Append DataFrame to the list\n",
    "                print(f\"Fetched {len(articles)} articles from {current_date.strftime('%Y-%m-%d')} to {batch_end_date.strftime('%Y-%m-%d')}\")\n",
    "                current_date = batch_end_date + timedelta(days=1)\n",
    "            elif response.status_code == 429:\n",
    "                print(\"Rate limit reached. Waiting to retry...\")\n",
    "                time.sleep(60)  # Wait for 60 seconds or as recommended by the API\n",
    "                continue  # Retry the current request\n",
    "            else:\n",
    "                print(f\"Failed to fetch data: {response.status_code}, {response.text}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            break\n",
    "\n",
    "    return pd.concat(all_news, ignore_index=True)\n",
    "\n",
    "#Usage\n",
    "api_key = os.environ.get('newsp_api')\n",
    "ticker = 'TSLA'\n",
    "end_date = datetime.now() - timedelta(days=1)  # Yesterday's date\n",
    "start_date = end_date - timedelta(days=365 * 2)\n",
    "news_articles = fetch_news(api_key, ticker, start_date, end_date)\n",
    "print(f\"Total articles fetched: {len(news_articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the news articles\n",
    "df = process_news_articles(news_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting the news articles into a csv\n",
    "df.to_csv('news_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = exponential_moving_average(df, window=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv('news_articles_ema.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_processed['date'].min())\n",
    "print(df_processed['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_processed['date'].max() - df_processed['date'].min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df_processed[df_processed.duplicated('date')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
