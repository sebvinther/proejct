{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import hopsworks \n",
    "from datetime import datetime, timedelta\n",
    "from SML.training_pipeline import model_dir\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#Making the notebook able to fetch from the .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get('hopsworks_api')\n",
    "project = hopsworks.login(api_key_value=api_key)\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.now() - timedelta(hours=48)\n",
    "print(start_date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.now() - timedelta(hours=24)\n",
    "print(end_date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view('tesla_stocks_fv', 5)\n",
    "feature_view.init_batch_scoring(training_dataset_version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_view.get_batch_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoding the tesla_df_b column 'ticker'\n",
    "\n",
    "tickers = tesla_df_b[['ticker']]\n",
    "\n",
    "# Initializing OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fitting and transforming the 'ticker' column\n",
    "ticker_encoded_test = encoder.fit_transform(tickers)\n",
    "\n",
    "# Converting the encoded column into a DataFrame\n",
    "ticker_encoded_df_test = pd.DataFrame(ticker_encoded_test.toarray(), columns=encoder.get_feature_names_out(['ticker']))\n",
    "\n",
    "# Concatenating the encoded DataFrame with the original DataFrame\n",
    "tesla_df_b = pd.concat([tesla_df_b, ticker_encoded_df_test], axis=1)\n",
    "\n",
    "# Dropping the original 'ticker' column\n",
    "tesla_df_b.drop('ticker', axis=1, inplace=True)\n",
    "# As X_train['date'] column exists and is in datetime format, we're converting it\n",
    "tesla_df_b['year'] = tesla_df_b['date'].dt.year\n",
    "tesla_df_b['month'] = tesla_df_b['date'].dt.month\n",
    "tesla_df_b['day'] = tesla_df_b['date'].dt.day\n",
    "\n",
    "# Dropping the original date column\n",
    "tesla_df_b.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Converting dataframe to numpy array\n",
    "tesla_df_b_array = tesla_df_b.to_numpy()\n",
    "\n",
    "# Reshaping the array to have a shape suitable for LSTM\n",
    "tesla_df_b_array = np.expand_dims(tesla_df_b_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "the_model = mr.get_model(\"stock_pred_model\", version=28)\n",
    "model_dir = the_model.download()\n",
    "\n",
    "model = joblib.load(model_dir + \"/stock_prediction_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(tesla_df_b_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Our predictions array\n",
    "predictions = np.array(predictions, dtype=np.float32)\n",
    "\n",
    "# Changing the format of the predicted value to correspond with format of \"open\"\n",
    "predictions = predictions[0][0]*100\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df_b['predictions'] = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 'year', 'month', and 'day' columns in your DataFrame\n",
    "tesla_df_b['date'] = pd.to_datetime(tesla_df_b[['year', 'month', 'day']])\n",
    "\n",
    "# Now you can drop the 'year', 'month', and 'day' columns if you want\n",
    "tesla_df_b.drop(columns=['year', 'month', 'day'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df_b['date'] = pd.to_datetime(tesla_df_b['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the encoded DataFrame back to numpy array\n",
    "ticker_encoded_array = ticker_encoded_df_test.to_numpy()\n",
    "\n",
    "# Inverse transform the encoded array to retrieve the original values\n",
    "original_tickers = encoder.inverse_transform(ticker_encoded_array)\n",
    "\n",
    "# Convert the original_tickers array to a DataFrame\n",
    "original_tickers_df = pd.DataFrame(original_tickers, columns=['ticker'])\n",
    "\n",
    "# Concatenate the original ticker column with the remaining columns from tesla_df_b\n",
    "tesla_df_b = pd.concat([tesla_df_b.drop(columns=['ticker_TSLA']), original_tickers_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Flatten the list of lists into a single list\n",
    "#flat_predictions_scaled = [item for sublist in predictions_scaled for item in sublist]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the scaled predictions\n",
    "#scaler.fit(flat_predictions_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions to get the original values\n",
    "#predictions_unscaled = scaler.inverse_transform(flat_predictions_scaled)\n",
    "\n",
    "# Update the 'predictions' column with the unscaled values\n",
    "#tesla_df_b['predictions'] = predictions_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get('hopsworks_api')\n",
    "project = hopsworks.login(api_key_value=api_key)\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fg = fs.get_or_create_feature_group(\n",
    "    name= 'stock_prediction_results',\n",
    "    version = 4,\n",
    "    description = 'Predction of TSLA open stock price',\n",
    "    primary_key = ['ticker'],\n",
    "    event_time = ['date'],\n",
    "    online_enabled = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserting the stock data into the stocks feature group\n",
    "results_fg.insert(tesla_df_b, write_options={\"wait_for_job\" : False})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
